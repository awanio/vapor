---
- name: Install Kubernetes prerequisites (Debian)
  block:
    - name: Install dependencies
      apt:
        name:
          - apt-transport-https
          - ca-certificates
          - curl
          - gpg
        state: present
    - name: Add Kubernetes Apt Key
      get_url:
        url: https://pkgs.k8s.io/core:/stable:/v{{ k8s_version }}/deb/Release.key
        dest: /etc/apt/keyrings/kubernetes-apt-keyring.asc
        mode: '0644'

    - name: Add Kubernetes Repository
      shell: |
        echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.asc] https://pkgs.k8s.io/core:/stable:/v{{ k8s_version }}/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list
    - name: Update apt index
      apt:
        update_cache: yes
    - name: Install kubelet, kubeadm, kubectl
      apt:
        name:
          - kubelet
          - kubeadm
          - kubectl
        state: present
    - name: Hold kubelet, kubeadm, kubectl
      dpkg_selections:
        name: "{{ item }}"
        selection: hold
      loop:
        - kubelet
        - kubeadm
        - kubectl
  when: ansible_os_family == "Debian"

# Setup kernel modules and sysctl
- name: Load overlay and br_netfilter modules
  modprobe:
    name: "{{ item }}"
    state: present
  loop:
    - overlay
    - br_netfilter

- name: Configure sysctl for Kubernetes
  sysctl:
    name: "{{ item.name }}"
    value: "{{ item.value }}"
    state: present
    sysctl_file: /etc/sysctl.d/k8s.conf
    reload: yes
  loop:
    - { name: 'net.bridge.bridge-nf-call-iptables', value: '1' }
    - { name: 'net.bridge.bridge-nf-call-ip6tables', value: '1' }
    - { name: 'net.ipv4.ip_forward', value: '1' }

# ... (Previous tasks remain, but we need to ensure they run on all nodes if needed)

# Initialize Cluster (Control Plane only)
- name: Detect cgroup version
  shell: |
    if [ -f /sys/fs/cgroup/cgroup.controllers ]; then
      echo "v2"
    else
      echo "v1"
    fi
  register: cgroup_check
  changed_when: false

- name: Set cgroup version fact
  set_fact:
    cgroup_version: "{{ cgroup_check.stdout }}"


- name: Disable swap immediately (cgroupv1)
  command: swapoff -a
  when: cgroup_version == "v1"
  changed_when: false

- name: Remove swap from fstab (cgroupv1)
  lineinfile:
    path: /etc/fstab
    regexp: "^[^#].*\\sswap\\s"
    state: absent
  when: cgroup_version == "v1"

- name: Check if cluster is already initialized
  stat:
    path: /etc/kubernetes/admin.conf
  register: k8s_conf
  when: node_role == "control-plane"

- name: Create kubeadm config
  template:
    src: kubeadm-config.yaml.j2
    dest: /etc/kubernetes/kubeadm-config.yaml
  when: node_role == "control-plane"

- name: Initialize Kubernetes Control Plane
  command: kubeadm init --config /etc/kubernetes/kubeadm-config.yaml --ignore-preflight-errors=Swap
  register: kubeadm_init
  when: 
    - node_role == "control-plane"
    - not k8s_conf.stat.exists

- name: Create .kube directory for user
  file:
    path: /root/.kube
    state: directory
    mode: '0755'
  when: node_role == "control-plane"

- name: Copy admin.conf to user's kube config
  copy:
    src: /etc/kubernetes/admin.conf
    dest: /root/.kube/config
    remote_src: yes
  when: node_role == "control-plane"

# Generate Join Command (Control Plane)
- name: Get join command
  command: kubeadm token create --print-join-command
  register: join_command_raw
  when: node_role == "control-plane"
  changed_when: false

- name: Set join command fact
  set_fact:
    join_command: "{{ join_command_raw.stdout_lines[0] }}"
  when: node_role == "control-plane"
  delegate_to: "{{ item }}"
  with_items: "{{ groups['all'] }}"
  run_once: yes 
  # This implies we need to share this fact. 
  # Better way: Register on CP, access via hostvars['localhost'] or the CP group name.
  # Let's rely on access via hostvars in the worker task.

# Join Cluster (Workers)
- name: Join cluster
  command: "{{ hostvars[groups['control_plane'][0]]['join_command'] }}"
  when: 
    - node_role == "worker"
    - install_k8s | bool
    # Check if already joined? "/etc/kubernetes/kubelet.conf" exists usually.
  args:
    creates: /etc/kubernetes/kubelet.conf


# CNI Installation
# CNI Installation
- name: Install Flannel CNI
  command: kubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf
  when: 
    - node_role == "control-plane"
    - cni_plugin == "flannel"
    # Basic check to avoid re-running every time, though kubectl apply is idempotent-ish
    # We can skip if we just init-ed (kubeadm_init changed) OR if we want to enforce it.
    # Let's keep it simple.

- name: Install Calico CNI
  command: kubectl apply -f https://raw.githubusercontent.com/projectcalico/calico/v3.27.0/manifests/calico.yaml
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf
  when: 
    - node_role == "control-plane"
    - cni_plugin == "calico"

- name: Install Cilium CNI (CLI install simplified)
  shell: |
    curl -L --remote-name-all https://github.com/cilium/cilium-cli/releases/latest/download/cilium-linux-amd64.tar.gz
    tar xzvfC cilium-linux-amd64.tar.gz /usr/local/bin
    rm cilium-linux-amd64.tar.gz
    cilium install
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf
  when: 
    - node_role == "control-plane"
    - cni_plugin == "cilium"

# Local Path Provisioner
- name: Install Local Path Provisioner
  command: kubectl apply -f https://raw.githubusercontent.com/rancher/local-path-provisioner/master/deploy/local-path-storage.yaml
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf
  when: 
    - node_role == "control-plane"
    - install_k8s | bool

- name: Patch Local Path Provisioner as default
  command: >
    kubectl patch storageclass local-path -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"true"}}}'
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf
  when:
    - node_role == "control-plane"
    - install_k8s | bool
